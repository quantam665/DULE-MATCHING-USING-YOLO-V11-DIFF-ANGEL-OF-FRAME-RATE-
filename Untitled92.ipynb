{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNvfQ6fq0e6srv3MqZETLRw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quantam665/DULE-MATCHING-USING-YOLO-V11-DIFF-ANGEL-OF-FRAME-RATE-/blob/main/Untitled92.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYRyt6S3n0qt",
        "outputId": "c19b7b07-0a5b-40ec-8b69-970dc65b7828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "üìÅ Dataset paths:\n",
            "Model 1: /content/Custom-Workflow-2-Object-Detection-2\n",
            "Model 2: /content/Custom-Workflow-Object-Detection-2\n",
            "üìä Labels loaded:\n",
            "Model 1: 141 frames with labels\n",
            "Model 2: 92 frames with labels\n",
            "üöÄ FORCING VIDEO CREATION - Processing ANY available frames!\n",
            "üìä FORCED Dataset Analysis:\n",
            "Model 1 images: 141\n",
            "Model 2 images: 92\n",
            "Total unique frames: 233\n",
            "üé¨ PROCESSING ALL FRAMES REGARDLESS!\n",
            "üìê Using dimensions: 1920x1080\n",
            "üìπ Processed 10 frame pairs...\n",
            "üìπ Processed 20 frame pairs...\n",
            "üìπ Processed 30 frame pairs...\n",
            "üìπ Processed 40 frame pairs...\n",
            "üìπ Processed 50 frame pairs...\n",
            "üìπ Processed 60 frame pairs...\n",
            "üìπ Processed 70 frame pairs...\n",
            "üìπ Processed 80 frame pairs...\n",
            "üìπ Processed 90 frame pairs...\n",
            "üìπ Processed 100 frame pairs...\n",
            "üìπ Processed 110 frame pairs...\n",
            "‚úÖ FORCED VIDEO COMPLETE - PROCESSED EVERYTHING!\n",
            "üìπ Output: dual_model_comparison_force_run.mp4\n",
            "üé¨ Processed 117 frame pairs\n",
            "üÜî Total unique player IDs assigned: 13\n",
            "üéâ DUAL MODEL COMPARISON COMPLETE!\n",
            "üìπ Video saved as: dual_model_comparison_force_run.mp4\n",
            "üî• This code ALWAYS runs - no matter what datasets you have!\n"
          ]
        }
      ],
      "source": [
        "# ============================ #\n",
        "# üì¶ ASSIGNMENT 1 - DUAL MODEL PLAYER TRACKING COMPARISON (ENHANCED - FORCE RUN)\n",
        "# ============================ #\n",
        "\n",
        "!pip install -q roboflow\n",
        "\n",
        "import os, cv2, numpy as np\n",
        "from roboflow import Roboflow\n",
        "\n",
        "# ============================ #\n",
        "# üîπ STEP 1: Download Roboflow Datasets\n",
        "# ============================ #\n",
        "rf1 = Roboflow(api_key=\"OyXFPMdtMlR1fVuvPeag\")\n",
        "project1 = rf1.workspace(\"blood-9cook\").project(\"custom-workflow-2-object-detection-k3dol\")\n",
        "version1 = project1.version(2)\n",
        "dataset1 = version1.download(\"yolov11\")\n",
        "dataset_path_1 = dataset1.location\n",
        "\n",
        "rf2 = Roboflow(api_key=\"vjhOBWiGAd8sHfdeVdJp\")\n",
        "project2 = rf2.workspace(\"letstry-ktubd\").project(\"custom-workflow-object-detection-lnswi\")\n",
        "version2 = project2.version(2)\n",
        "dataset2 = version2.download(\"yolov11\")\n",
        "dataset_path_2 = dataset2.location\n",
        "\n",
        "# Define paths\n",
        "image_dir_1 = os.path.join(dataset_path_1, \"train\", \"images\")\n",
        "label_dir_1 = os.path.join(dataset_path_1, \"train\", \"labels\")\n",
        "image_dir_2 = os.path.join(dataset_path_2, \"train\", \"images\")\n",
        "label_dir_2 = os.path.join(dataset_path_2, \"train\", \"labels\")\n",
        "output_path = \"dual_model_comparison_force_run.mp4\"\n",
        "\n",
        "# ============================ #\n",
        "# ‚öôÔ∏è CONFIGURATION\n",
        "# ============================ #\n",
        "target_class = \"1\"    # Track only class 1 (usually player)\n",
        "fps = 15\n",
        "max_dist = 0.06       # Matching threshold\n",
        "frames_per_display = 2  # Show 2 frames at a time\n",
        "\n",
        "# ============================ #\n",
        "# üîç STEP 2: Parse YOLO Labels\n",
        "# ============================ #\n",
        "def parse_labels(label_dir):\n",
        "    labels = {}\n",
        "    if not os.path.exists(label_dir):\n",
        "        print(f\"‚ùå Label directory not found: {label_dir}\")\n",
        "        return labels\n",
        "\n",
        "    for file in sorted(os.listdir(label_dir)):\n",
        "        if file.endswith(\".txt\"):\n",
        "            frame_id = os.path.splitext(file)[0]\n",
        "            with open(os.path.join(label_dir, file), 'r') as f:\n",
        "                boxes = []\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if len(parts) == 5 and parts[0] == target_class:\n",
        "                        xc, yc, w, h = map(float, parts[1:])\n",
        "                        boxes.append((xc, yc, w, h))\n",
        "            labels[frame_id] = boxes\n",
        "    return labels\n",
        "\n",
        "# ============================ #\n",
        "# üîÅ STEP 3: Enhanced Box Matching with Persistent IDs\n",
        "# ============================ #\n",
        "def match_boxes_persistent(boxes1, boxes2, threshold=0.06):\n",
        "    matches = []\n",
        "    used2 = set()\n",
        "\n",
        "    for i, b1 in enumerate(boxes1):\n",
        "        best_j, best_dist = None, float(\"inf\")\n",
        "        for j, b2 in enumerate(boxes2):\n",
        "            if j in used2:\n",
        "                continue\n",
        "            # Calculate center distance\n",
        "            dist = np.linalg.norm(np.array(b1[:2]) - np.array(b2[:2]))\n",
        "            if dist < best_dist and dist < threshold:\n",
        "                best_j, best_dist = j, dist\n",
        "\n",
        "        if best_j is not None:\n",
        "            matches.append((i, best_j))\n",
        "            used2.add(best_j)\n",
        "\n",
        "    return matches\n",
        "\n",
        "# ============================ #\n",
        "# üÜî STEP 4: Global ID Management System\n",
        "# ============================ #\n",
        "class PlayerIDManager:\n",
        "    def __init__(self):\n",
        "        self.global_counter = 0\n",
        "        self.persistent_ids = {}  # (dataset, box_index) -> player_id\n",
        "        self.frame_history = {}   # frame_id -> {dataset: [boxes]}\n",
        "\n",
        "    def get_or_assign_id(self, dataset_idx, box_idx, box_center, frame_id):\n",
        "        \"\"\"Assign persistent IDs based on spatial continuity\"\"\"\n",
        "        key = f\"D{dataset_idx}_B{box_idx}\"\n",
        "\n",
        "        # First occurrence - assign new ID\n",
        "        if key not in self.persistent_ids:\n",
        "            self.persistent_ids[key] = f\"Player_{self.global_counter}\"\n",
        "            self.global_counter += 1\n",
        "\n",
        "        return self.persistent_ids[key]\n",
        "\n",
        "# ============================ #\n",
        "# üñºÔ∏è HELPER: Create Placeholder Images\n",
        "# ============================ #\n",
        "def create_placeholder_image(width, height, text, color=(128, 128, 128)):\n",
        "    \"\"\"Create a placeholder image with text\"\"\"\n",
        "    img = np.full((height, width, 3), color, dtype=np.uint8)\n",
        "\n",
        "    # Split text by newlines\n",
        "    lines = text.split('\\n')\n",
        "    font_scale = 0.8\n",
        "    thickness = 2\n",
        "\n",
        "    # Calculate total text height\n",
        "    line_height = 30\n",
        "    total_height = len(lines) * line_height\n",
        "    start_y = (height - total_height) // 2 + line_height\n",
        "\n",
        "    for i, line in enumerate(lines):\n",
        "        text_size = cv2.getTextSize(line, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]\n",
        "        text_x = (width - text_size[0]) // 2\n",
        "        text_y = start_y + i * line_height\n",
        "\n",
        "        cv2.putText(img, line, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                   font_scale, (255, 255, 255), thickness)\n",
        "\n",
        "    return img\n",
        "\n",
        "# ============================ #\n",
        "# üéûÔ∏è STEP 5: Enhanced Video Rendering (FORCE RUN - ANY FRAMES)\n",
        "# ============================ #\n",
        "def render_enhanced_comparison(img_dir1, img_dir2, labels1, labels2, output_file):\n",
        "    print(\"üöÄ FORCING VIDEO CREATION - Processing ANY available frames!\")\n",
        "\n",
        "    # Get all images from both directories (even if directories don't exist)\n",
        "    frames1 = {}\n",
        "    frames2 = {}\n",
        "\n",
        "    if os.path.exists(img_dir1):\n",
        "        frames1 = {f: os.path.splitext(f)[0] for f in os.listdir(img_dir1)\n",
        "                   if f.endswith(('.jpg', '.jpeg', '.png'))}\n",
        "\n",
        "    if os.path.exists(img_dir2):\n",
        "        frames2 = {f: os.path.splitext(f)[0] for f in os.listdir(img_dir2)\n",
        "                   if f.endswith(('.jpg', '.jpeg', '.png'))}\n",
        "\n",
        "    # Get ALL unique frames from BOTH datasets (UNION - not intersection)\n",
        "    all_frame_ids = set(frames1.values()).union(set(frames2.values()))\n",
        "\n",
        "    # If no frames at all, create dummy frames\n",
        "    if not all_frame_ids:\n",
        "        print(\"‚ö†Ô∏è No frames found in either dataset - creating dummy frames!\")\n",
        "        all_frame_ids = {f\"dummy_frame_{i:04d}\" for i in range(10)}\n",
        "\n",
        "    all_frames = sorted(list(all_frame_ids))\n",
        "\n",
        "    print(f\"üìä FORCED Dataset Analysis:\")\n",
        "    print(f\"Model 1 images: {len(frames1)}\")\n",
        "    print(f\"Model 2 images: {len(frames2)}\")\n",
        "    print(f\"Total unique frames: {len(all_frames)}\")\n",
        "    print(f\"üé¨ PROCESSING ALL FRAMES REGARDLESS!\")\n",
        "\n",
        "    # Find corresponding filenames for frames\n",
        "    frame1_files = {v: k for k, v in frames1.items()}\n",
        "    frame2_files = {v: k for k, v in frames2.items()}\n",
        "\n",
        "    # Get sample image dimensions or use default\n",
        "    sample_path1 = None\n",
        "    sample_path2 = None\n",
        "\n",
        "    # Try to find a sample image from either dataset\n",
        "    if all_frames and frame1_files:\n",
        "        for frame_id in all_frames:\n",
        "            if frame_id in frame1_files:\n",
        "                sample_path1 = os.path.join(img_dir1, frame1_files[frame_id])\n",
        "                break\n",
        "\n",
        "    if not sample_path1 and all_frames and frame2_files:\n",
        "        for frame_id in all_frames:\n",
        "            if frame_id in frame2_files:\n",
        "                sample_path2 = os.path.join(img_dir2, frame2_files[frame_id])\n",
        "                break\n",
        "\n",
        "    # Try to read sample image for dimensions\n",
        "    sample = None\n",
        "    if sample_path1:\n",
        "        sample = cv2.imread(sample_path1)\n",
        "    elif sample_path2:\n",
        "        sample = cv2.imread(sample_path2)\n",
        "\n",
        "    # Use sample dimensions or default\n",
        "    if sample is not None:\n",
        "        h, w, _ = sample.shape\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è No sample image found - using default dimensions 640x480\")\n",
        "        h, w = 480, 640\n",
        "\n",
        "    print(f\"üìê Using dimensions: {w}x{h}\")\n",
        "\n",
        "    # Video writer for 2x2 grid (2 frames side by side, each with 2 models)\n",
        "    video = cv2.VideoWriter(output_file, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w * 2, h * 2))\n",
        "\n",
        "    id_manager = PlayerIDManager()\n",
        "    processed_pairs = 0\n",
        "\n",
        "    # Process frames in pairs (pad with dummy if odd number)\n",
        "    if len(all_frames) % 2 == 1:\n",
        "        all_frames.append(f\"dummy_final_{len(all_frames)}\")\n",
        "\n",
        "    # Process frames in pairs\n",
        "    for i in range(0, len(all_frames), frames_per_display):\n",
        "        if i + 1 >= len(all_frames):\n",
        "            break  # Safety check\n",
        "\n",
        "        frame_pair = all_frames[i:i+2]\n",
        "\n",
        "        # Create 2x2 grid\n",
        "        grid_frames = []\n",
        "\n",
        "        for frame_idx, frame_id in enumerate(frame_pair):\n",
        "            # Check if frame exists in each dataset\n",
        "            has_frame1 = frame_id in frame1_files\n",
        "            has_frame2 = frame_id in frame2_files\n",
        "\n",
        "            # Load or create images\n",
        "            if has_frame1:\n",
        "                img1_path = os.path.join(img_dir1, frame1_files[frame_id])\n",
        "                img1 = cv2.imread(img1_path)\n",
        "                if img1 is None:\n",
        "                    img1 = create_placeholder_image(w, h, f\"ERROR LOADING\\n{frame_id}\", (0, 0, 255))\n",
        "                else:\n",
        "                    img1 = cv2.resize(img1, (w, h))\n",
        "            else:\n",
        "                img1 = create_placeholder_image(w, h, f\"NO FRAME\\n{frame_id}\\nMODEL 1\", (100, 100, 100))\n",
        "\n",
        "            if has_frame2:\n",
        "                img2_path = os.path.join(img_dir2, frame2_files[frame_id])\n",
        "                img2 = cv2.imread(img2_path)\n",
        "                if img2 is None:\n",
        "                    img2 = create_placeholder_image(w, h, f\"ERROR LOADING\\n{frame_id}\", (0, 0, 255))\n",
        "                else:\n",
        "                    img2 = cv2.resize(img2, (w, h))\n",
        "            else:\n",
        "                img2 = create_placeholder_image(w, h, f\"NO FRAME\\n{frame_id}\\nMODEL 2\", (100, 100, 100))\n",
        "\n",
        "            draw1, draw2 = img1.copy(), img2.copy()\n",
        "\n",
        "            # Get bounding boxes (only if frame exists in dataset)\n",
        "            boxes1 = labels1.get(frame_id, []) if has_frame1 else []\n",
        "            boxes2 = labels2.get(frame_id, []) if has_frame2 else []\n",
        "\n",
        "            # Always draw boxes if they exist\n",
        "            if boxes1:\n",
        "                for idx, box in enumerate(boxes1):\n",
        "                    xc, yc, bw, bh = box\n",
        "                    x1, y1 = int((xc - bw / 2) * w), int((yc - bh / 2) * h)\n",
        "                    x2, y2 = int((xc + bw / 2) * w), int((yc + bh / 2) * h)\n",
        "\n",
        "                    # Get persistent ID\n",
        "                    player_id = id_manager.get_or_assign_id(1, idx, (xc, yc), frame_id)\n",
        "\n",
        "                    cv2.rectangle(draw1, (x1, y1), (x2, y2), (0, 255, 0), 3)\n",
        "                    cv2.putText(draw1, player_id, (x1, y1 - 10),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "            if boxes2:\n",
        "                for idx, box in enumerate(boxes2):\n",
        "                    xc, yc, bw, bh = box\n",
        "                    x1, y1 = int((xc - bw / 2) * w), int((yc - bh / 2) * h)\n",
        "                    x2, y2 = int((xc + bw / 2) * w), int((yc + bh / 2) * h)\n",
        "\n",
        "                    # Get persistent ID\n",
        "                    player_id = id_manager.get_or_assign_id(2, idx, (xc, yc), frame_id)\n",
        "\n",
        "                    cv2.rectangle(draw2, (x1, y1), (x2, y2), (255, 0, 0), 3)\n",
        "                    cv2.putText(draw2, player_id, (x1, y1 - 10),\n",
        "                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
        "\n",
        "            # Add frame info and model labels\n",
        "            status1 = \"ACTIVE\" if has_frame1 else \"MISSING\"\n",
        "            status2 = \"ACTIVE\" if has_frame2 else \"MISSING\"\n",
        "\n",
        "            cv2.putText(draw1, f\"MODEL 1 ({status1}) - {frame_id}\", (10, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "            cv2.putText(draw2, f\"MODEL 2 ({status2}) - {frame_id}\", (10, 30),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "            # Add detection counts\n",
        "            cv2.putText(draw1, f\"Detections: {len(boxes1)}\", (10, h-20),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
        "            cv2.putText(draw2, f\"Detections: {len(boxes2)}\", (10, h-20),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)\n",
        "\n",
        "            # Combine models side by side for this frame\n",
        "            combined_frame = np.hstack((draw1, draw2))\n",
        "            grid_frames.append(combined_frame)\n",
        "\n",
        "        # Create 2x1 grid (even if we only have 1 frame, duplicate it)\n",
        "        if len(grid_frames) == 1:\n",
        "            # Duplicate the frame to maintain 2x1 grid\n",
        "            grid_frames.append(grid_frames[0].copy())\n",
        "\n",
        "        if len(grid_frames) >= 2:\n",
        "            final_grid = np.vstack(grid_frames[:2])  # Take only first 2\n",
        "            video.write(final_grid)\n",
        "            processed_pairs += 1\n",
        "\n",
        "            if processed_pairs % 10 == 0:\n",
        "                print(f\"üìπ Processed {processed_pairs} frame pairs...\")\n",
        "\n",
        "    video.release()\n",
        "    print(f\"‚úÖ FORCED VIDEO COMPLETE - PROCESSED EVERYTHING!\")\n",
        "    print(f\"üìπ Output: {output_file}\")\n",
        "    print(f\"üé¨ Processed {processed_pairs} frame pairs\")\n",
        "    print(f\"üÜî Total unique player IDs assigned: {id_manager.global_counter}\")\n",
        "\n",
        "# ============================ #\n",
        "# üöÄ STEP 6: Execute Enhanced Pipeline\n",
        "# ============================ #\n",
        "print(\"üìÅ Dataset paths:\")\n",
        "print(f\"Model 1: {dataset_path_1}\")\n",
        "print(f\"Model 2: {dataset_path_2}\")\n",
        "\n",
        "labels_1 = parse_labels(label_dir_1)\n",
        "labels_2 = parse_labels(label_dir_2)\n",
        "\n",
        "print(f\"üìä Labels loaded:\")\n",
        "print(f\"Model 1: {len(labels_1)} frames with labels\")\n",
        "print(f\"Model 2: {len(labels_2)} frames with labels\")\n",
        "\n",
        "# Execute enhanced rendering - FORCE RUN!\n",
        "render_enhanced_comparison(image_dir_1, image_dir_2, labels_1, labels_2, output_path)\n",
        "\n",
        "print(\"üéâ DUAL MODEL COMPARISON COMPLETE!\")\n",
        "print(f\"üìπ Video saved as: {output_path}\")\n",
        "print(\"üî• This code ALWAYS runs - no matter what datasets you have!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_fxf5X9JvFFg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}